{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRTMPFP2vGIU"
   },
   "source": [
    "## Actalizando la información de los LLMs\n",
    "\n",
    "Una gran limitación de los  LLMS es que almacenan toda la información en sus parámetros que son ajustados en el momento de entrenamiento. Dentro de la memoria de ChatGPT hay almacenada una gran cantidad de datos de la realidad que:\n",
    "* Se repitieron en los textos de entrenamiento de la etapa no supervisada (predicción del texto que sigue)\n",
    "\n",
    "* Fueron parte de las respuestas escritas por humanos en la etapa supervisada\n",
    "\n",
    "* Fueron etiquetadas por un humano como correctas (:thumbsup:) en la etapa de RLHF\n",
    "\n",
    "Miren el siguiente ejemplo:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u28gLBDJwVzt"
   },
   "source": [
    "<img src=\"https://i.ibb.co/wp3vrv5/Screen-Shot-2023-09-17-at-17-03-57.png\" width=\"500px\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_LP9EDnxEQl"
   },
   "source": [
    "Pero ¿Qué pasa si necesitamos datos recientes?\n",
    "\n",
    "<img src=\"https://i.ibb.co/rMj3ScT/Whats-App-Image-2023-09-13-at-13-36-03-1.jpg\" width=\"500px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TD1AN2yyP3R"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# Tiene formato de código\n",
    "```\n",
    "\n",
    "Desde la aparición de los LLMs cobraron gran importancia las herramientas capaces de proveer información textual en tiempo real, como las bases de datos vectoriales (que vamos a ver más adelante en el curso) y los motores de búsqueda consumidos a través de APIs como Bing y <a href=\"https://serpapi.com/\">SERP API</a>, que utiliza web scraping de los resultados orgánicos de Google.\n",
    "\n",
    "Existen aplicaciones para usuarios finales que ya permiten combinar la capacidad de razonamiento de los LLMs con estos grandes índices de información actualizada como https://www.bing.com/chat y https://www.perplexity.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bb606YkDzneD"
   },
   "source": [
    "<img src=\"https://i.ibb.co/VQ27VQZ/Whats-App-Image-2023-09-13-at-13-36-03.jpg\" width=\"500px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4k8usXD0IN5"
   },
   "source": [
    "## Ejercicio\n",
    "\n",
    "Les proponemos utilizar las APIs de SERP y OpenAI para responder preguntas de actualidad, como por ejemplo ¿Quién ganó las elecciones de Argentina 2023? Exploremos un sistema capaz de responder a cualquier pregunta de actualidad.\n",
    "\n",
    "Para poder resolver este ejercicio vamos a utilizar dos sistemas externos: SERP API y OpenAI. Ambos tienen consumos de prueba que se pueden utilizar para explorar, pero cuando integramos este tipo de servicios a nuestras tenemos que considerar:\n",
    "\n",
    "1) Los costos: https://serpapi.com/pricing // https://openai.com/pricing\n",
    "\n",
    "2) Seguridad: ¡Cuidado! Las claves privadas son lo único que se necesita para acceder con una identidad. En los sistemas productivos las claves se encuentran en un archivo de configuración (.env) y JAMÁS se deben subir a los repositorios de código como git. Normalmente se excluye al .env del repositorio utilizando el archivo .gitignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7025,
     "status": "ok",
     "timestamp": 1755905267680,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "y1I3fR-lWxtl",
    "outputId": "872a1082-85dd-4a0b-c41f-c8ea236f1a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Instalamos las librerías\n",
    "!pip install google-search-results openai dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1. Registrarse a SERP API y Open AI para obetener las siguientes claves\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "SERP_API_KEY = os.getenv(\"SERP_API_KEY\")\n",
    "#OPENAI_ORGANIZATION = userdata.get(\"OPENAI_ORGANIZATION\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1755905277244,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "hvmGwWXXwRce"
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from dataclasses import dataclass\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class SnippetCitation:\n",
    "    Url: str\n",
    "    Title: str\n",
    "    Snippet: str\n",
    "\n",
    "def serp_results(query: str, num=5, api_key=SERP_API_KEY):\n",
    "  params = {\n",
    "      \"engine\": \"google\",\n",
    "      \"q\": query,\n",
    "      \"api_key\": api_key,\n",
    "      \"num\":num\n",
    "  }\n",
    "  search = GoogleSearch(params)\n",
    "  res = search.get_dict()\n",
    "  organic_results = res.get(\"organic_results\", []) # Add this line to safely access the key\n",
    "  return_results = []\n",
    "  for result in organic_results:\n",
    "      try:\n",
    "        return_results.append(SnippetCitation(Url=result[\"link\"], Title=result[\"title\"], Snippet=result[\"snippet\"]))\n",
    "      except Exception as e:\n",
    "          print(e)\n",
    "  return return_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1755905305379,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "Rkwwb-E7asDf",
    "outputId": "f2acd9cb-5bd7-4fa7-e501-f312afc63d67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SnippetCitation(Url='https://es.wikipedia.org/wiki/Francisco_(papa)', Title='Francisco (papa) - Wikipedia, la enciclopedia libre', Snippet='Jorge Mario Bergoglio · Francisco · 17 de diciembre de 1936. Buenos Aires, Argentina · 21 de abril de 2025 (88 años) Domus Sanctae Marthae, Ciudad del Vaticano.'),\n",
       " SnippetCitation(Url='http://buenosaires.gob.ar/biografiapapafrancisco', Title='El Papa Francisco, su biografía', Snippet='Tras la renuncia de Benedicto XVI, y durante el cónclave, el 13 de marzo de 2013 Jorge Bergoglio fue elegido Papa. Adoptó el nombre de Francisco y desde su ...'),\n",
       " SnippetCitation(Url='https://www.nationalgeographicla.com/historia/2025/05/habemus-papam-leon-xiv-es-el-nuevo-papa-conoce-cuales-son-los-nombres-papales-mas-utilizados-de-la-historia', Title='León XIV es el nuevo papa. Conoce cuáles son los nombres ...', Snippet='León: hasta 2024 hubo 13 papas con este nombre. Robert Francis Prévost, el cardenal elegido como sucesor del papa Francisco, también lo eligió, ...')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serp_res = serp_results(\"¿Cual es el nombre del Papa?\")\n",
    "serp_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9gPBfR7b9xh"
   },
   "source": [
    "# Paso 3\n",
    "\n",
    "Utilizar GPT para responder a la pregunta.\n",
    "\n",
    "Siguiendo la documentación de la API de OpenAI, escriban una función para generar texto simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1755905310241,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "ZA6RjUKUa03L"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1755905312182,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "iwQCl9r6NpQL"
   },
   "outputs": [],
   "source": [
    "  # Uses OPENAI_API_KEY environment variable\n",
    "\n",
    "def chat_complete(\n",
    "    syst: str | None,\n",
    "    user: list[str] = [],\n",
    "    assistant: list[str] = [],\n",
    "    max_tokens: int = 1024,\n",
    "    temperature: float = 0,\n",
    "    model: str = \"gpt-4o\",\n",
    ") -> str:\n",
    "    # Initialize the OpenAI client\n",
    "    messages: list[dict[str, str]] = []\n",
    "\n",
    "    if syst is not None:\n",
    "        messages.append({\"role\": \"system\", \"content\": syst})\n",
    "\n",
    "    for i in range(len(user)):\n",
    "        messages.append({\"role\": \"user\", \"content\": user[i]})\n",
    "        if len(assistant) > i:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant[i]})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1755905315805,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "oTJJ4KlqeYbK",
    "outputId": "78d9c2ed-ff7b-4b3a-a731-554c0c7c941b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'¡Hola! ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_complete(\"Hola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbFIFJICfPsM"
   },
   "source": [
    "# Paso 4\n",
    "\n",
    "Pensemos un buen prompt que pueda tomar como contexto la información obtenida de SERP API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1755905318779,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "RjLCl-LbedWk"
   },
   "outputs": [],
   "source": [
    "\n",
    "SYSTEM_PROMPT = \"\"\"Tu objetivo es responder a la pregunta [PREGUNTA] utilizando este contexto [CONTEXTO].\n",
    "\n",
    "Si la respuesta no se encuentra en el contexto, responde que no sabes. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1755905333721,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "vp7OAn8NfvMV"
   },
   "outputs": [],
   "source": [
    "pregunta = \"¿Cual es el nombre del Papa?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1755905334837,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "NbImV4Qgf2uE"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[PREGUNTA]\", pregunta)\n",
    "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[CONTEXTO]\", str(serp_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1755905337453,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "uy0UA0DfgI_x",
    "outputId": "0a48ed92-b23b-43b4-ad3f-527e32662751"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'El nombre del Papa es Francisco, cuyo nombre de nacimiento es Jorge Mario Bergoglio.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_complete(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scDeCPb0TYFQ"
   },
   "source": [
    "# Paso 6\n",
    "\n",
    "Darle una forma estructurada a las respuestas.\n",
    "\n",
    "Ahora vamos a adaptar la función chat_complete para recibir como parámetro el schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1755905346671,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "iDPMA07dSZNV"
   },
   "outputs": [],
   "source": [
    "def limpiar_markdown(content: str):\n",
    "    # Remove markdown code block markers\n",
    "    content = content.strip()\n",
    "    if content.startswith('```json'):\n",
    "        content = content[7:]  # Remove ```json\n",
    "    elif content.startswith('```'):\n",
    "        content = content[3:]   # Remove ```\n",
    "    if content.endswith('```'):\n",
    "        content = content[:-3]  # Remove closing ```\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1755905348852,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "oGProC82RiGG"
   },
   "outputs": [],
   "source": [
    "def chat_complete(\n",
    "    syst: str | None,\n",
    "    user: list[str] = [],\n",
    "    assistant: list[str] = [],\n",
    "    max_tokens: int = 1024,\n",
    "    temperature: float = 0,\n",
    "    model: str = \"gpt-4o\",\n",
    "    schema: dict | None = None\n",
    ") -> str:\n",
    "    # Initialize the OpenAI client\n",
    "    messages: list[dict[str, str]] = []\n",
    "\n",
    "    if syst is not None:\n",
    "        messages.append({\"role\": \"system\", \"content\": syst})\n",
    "\n",
    "    for i in range(len(user)):\n",
    "        messages.append({\"role\": \"user\", \"content\": user[i]})\n",
    "        if len(assistant) > i:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant[i]})\n",
    "\n",
    "    # Build the request parameters\n",
    "    request_params = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "    if schema is not None:\n",
    "        request_params[\"response_format\"] = {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"structured_response\",\n",
    "                \"schema\": schema,\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "    response = client.chat.completions.create(**request_params)\n",
    "    content = response.choices[0].message.content\n",
    "    content = limpiar_markdown(content)\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1755905354571,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "7Iu23GuzXOIs"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"Tu objetivo es responder a la pregunta [PREGUNTA] utilizando este contexto [CONTEXTO].\n",
    "\n",
    "El formato de salida debe ser un array de json con todas las entidades mencionadas. Cada una representada como un único string del título \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1755905357337,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "dRqCf2OOXZh2"
   },
   "outputs": [],
   "source": [
    "pregunta = \"Recomendaciones de series 2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 1311,
     "status": "ok",
     "timestamp": 1755905360263,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "8Iw1hcp8XooM"
   },
   "outputs": [],
   "source": [
    "serp_res = serp_results(pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1755905361514,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "WmMaZnWhXwx2"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[PREGUNTA]\", pregunta)\n",
    "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[CONTEXTO]\", str(serp_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1755905362688,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "U5pBjffiQ5nk"
   },
   "outputs": [],
   "source": [
    "# Ahora representemos en un diccionario un esquema con un array de string\n",
    "RECOMMENDATIONS_SCHEMA = {\n",
    "    \"type\": \"ARRAY\",\n",
    "    \"items\": {\n",
    "        \"type\": \"STRING\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 2416,
     "status": "ok",
     "timestamp": 1755905366637,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "nZ4qjvnyX2Gf"
   },
   "outputs": [],
   "source": [
    "json_list = chat_complete(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1755905367480,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "Cxb4C9QXX3_W",
    "outputId": "f3f94789-8806-4772-f0cc-4b5ffb997c97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Takopi's Original Sin\",\n",
       " 'Si la vida te da mandarinas',\n",
       " 'The Pitt',\n",
       " 'Efectos secundarios',\n",
       " 'Tierra de',\n",
       " 'The Bear (T4)',\n",
       " 'El Eternauta',\n",
       " 'DanDaDan (T2)',\n",
       " 'M: Il figlio del secolo',\n",
       " 'Daredevil',\n",
       " 'Stranger Things',\n",
       " 'Miércoles',\n",
       " 'Alien',\n",
       " 'Blade Runner']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(json_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2w6JY4wZBxp"
   },
   "source": [
    "# Paso 7. Bonus\n",
    "\n",
    "Como extra, hagamos una función que nos indique dónde ver cada una de las series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1755905376207,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "hoiUSJzFZNHs"
   },
   "outputs": [],
   "source": [
    "shows = json.loads(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1755905378414,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "xN8xEtzWZO3e"
   },
   "outputs": [],
   "source": [
    "def get_streaming_service(show:str):\n",
    "  SYSTEM_PROMPT = \"\"\"Tu objetivo es responder a la pregunta [PREGUNTA] utilizando este contexto [CONTEXTO].\"\"\"\n",
    "  pregunta = f\"¿Dónde puedo ver la serie {show}?\"\n",
    "  contexto = serp_results(pregunta)\n",
    "  SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[PREGUNTA]\", pregunta)\n",
    "  SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[CONTEXTO]\", str(contexto))\n",
    "  streaming = chat_complete(SYSTEM_PROMPT)\n",
    "  print(show,\"-->\" ,streaming)\n",
    "  return (show, streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10990,
     "status": "ok",
     "timestamp": 1755905391377,
     "user": {
      "displayName": "Matias Barreto (devenirfantasma)",
      "userId": "07072764524169679349"
     },
     "user_tz": 180
    },
    "id": "Qy8HyKlDaM8D",
    "outputId": "a281f2fa-61e8-4266-fe8e-00c79a3abda4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takopi's Original Sin --> Puedes ver la serie \"Takopi's Original Sin\" en Crunchyroll. También está disponible en el canal de Crunchyroll en Amazon.\n",
      "Si la vida te da mandarinas --> Puedes ver la serie \"Si la vida te da mandarinas\" en Netflix.\n",
      "The Pitt --> Puedes ver la serie \"The Pitt\" en HBO Max, Hulu y Prime Video.\n",
      "Efectos secundarios --> Puedes ver la serie \"Efectos secundarios\" en streaming en HBO Max y Movistar Plus+ Ficción Total. También está disponible en el canal de HBO Max en Amazon.\n",
      "Tierra de --> Puedes ver la serie \"Tierra de Reyes\" en línea a través de la app de Telemundo para iOS y Android, en tu smart TV (Roku, Fire TV, Apple TV, Samsung), en Hulu y en Prime Video.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# Hagamos sólo 5 para ahorrar costos\n",
    "for show in shows[:5]:\n",
    "  results.append(get_streaming_service(show))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1JDV74frsDV9kRVW3UIqAh3WqlQ9Zs6kF",
     "timestamp": 1755898384250
    },
    {
     "file_id": "1Un8xBD6s6wO1Q8BHBJxJG32yujKpiid7",
     "timestamp": 1754675131910
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
