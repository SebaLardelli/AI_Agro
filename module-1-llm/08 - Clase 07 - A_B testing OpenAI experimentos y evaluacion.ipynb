{"cells":[{"cell_type":"markdown","id":"46e93e49","metadata":{"id":"46e93e49"},"source":["# A/B Testing para Evaluar Estrategias de Prompting (OpenAI)\n","\n","Este cuaderno es una versi√≥n del experimento original (con Gemini) adaptada para usar la API de OpenAI. Est√° dise√±ado para ejecutarse tanto en local (usando un archivo `.env`) como en Google Colab (usando `userdata.get` para obtener secrets)."]},{"cell_type":"markdown","id":"8858a5eb","metadata":{"id":"8858a5eb"},"source":["## 1) Configuraci√≥n de entorno (Local / Colab)\n","\n","El cuaderno detecta autom√°ticamente si se est√° ejecutando en Colab y carga la clave de la forma apropiada. Si trabajas localmente, aseg√∫rate de tener un archivo `.env` con `OPENAI_API_KEY`.\n","\n","Nota: ya tienes una `.env` en este directorio, as√≠ que no deber√≠as necesitar cambios adicionales para ejecuci√≥n local."]},{"cell_type":"code","execution_count":null,"id":"03435ce6","metadata":{"id":"03435ce6"},"outputs":[],"source":["import os\n","import sys\n","import pandas as pd\n","from dotenv import load_dotenv\n","\n","# Intentar detectar Colab\n","IN_COLAB = False\n","try:\n","    import google.colab\n","    from google.colab import userdata\n","    IN_COLAB = True\n","except Exception:\n","    IN_COLAB = False\n","\n","# Cargar .env si existe (√∫til en local)\n","load_dotenv()\n","\n","OPENAI_API_KEY = None\n","if IN_COLAB:\n","    # En Colab el usuario puede guardar secretos y recuperarlos con userdata.get\n","    try:\n","        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","    except Exception:\n","        OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","else:\n","    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","\n","if not OPENAI_API_KEY:\n","    raise ValueError('OPENAI_API_KEY no encontrada. Coloca tu clave en .env o en Colab secrets con la key OPENAI_API_KEY')\n","\n","print(f\"‚úÖ OPENAI key cargada. Entorno: {'Colab' if IN_COLAB else 'Local'}\")"]},{"cell_type":"markdown","id":"2f29aa8c","metadata":{"id":"2f29aa8c"},"source":["## 2) Inicializar cliente de OpenAI\n","\n","Usamos la librer√≠a oficial `openai` (cliente moderno `OpenAI`). Si no la tienes instalada, instala con `pip install openai python-dotenv ipywidgets`."]},{"cell_type":"code","execution_count":null,"id":"934ff951","metadata":{"id":"934ff951"},"outputs":[],"source":["from openai import OpenAI\n","\n","# Inicializar cliente pasando la api_key directamente para evitar dependencias del entorno\n","client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","print('‚úÖ Cliente OpenAI inicializado')"]},{"cell_type":"markdown","id":"8c2dd192","metadata":{"id":"8c2dd192"},"source":["## 3) Prompts: Variante A (Zero-shot) y Variante B (Few-shot)"]},{"cell_type":"code","execution_count":null,"id":"cd8451cc","metadata":{"id":"cd8451cc"},"outputs":[],"source":["prompt_A = \"\"\"Descripci√≥n de la pr√°ctica: Optimizaci√≥n del uso del agua en cultivos de secano mediante t√©cnicas de conservaci√≥n de humedad.\n","\n","Palabras clave: conservaci√≥n agua, secano, humedad suelo, optimizaci√≥n.\n","\n","Temas relacionados:\"\"\"\n","\n","prompt_B = \"\"\"Descripci√≥n de la pr√°ctica: Implementaci√≥n de rotaci√≥n de cultivos para mejorar la salud del suelo y reducir plagas.\n","\n","Palabras clave: rotaci√≥n cultivos, salud suelo, manejo plagas, sostenibilidad.\n","\n","Temas relacionados: Agroecolog√≠a, Manejo Integrado de Plagas, Fertilizaci√≥n Natural, Diversificaci√≥n Agr√≠cola.\n","\n","\n","Descripci√≥n de la pr√°ctica: Uso de drones para monitoreo de cultivos y detecci√≥n temprana de enfermedades.\n","\n","Palabras clave: drones agricultura, monitoreo cultivos, detecci√≥n enfermedades, agricultura precisi√≥n.\n","\n","Temas relacionados: Teledetecci√≥n Agr√≠cola, Agricultura Inteligente, Sensores Remotos, An√°lisis de Im√°genes A√©reas.\n","\n","\n","Descripci√≥n de la pr√°ctica: Optimizaci√≥n del uso del agua en cultivos de secano mediante t√©cnicas de conservaci√≥n de humedad.\n","\n","Palabras clave: conservaci√≥n agua, secano, humedad suelo, optimizaci√≥n.\n","\n","Temas relacionados:\"\"\"\n","\n","print('üìù Prompt A (Zero-shot) - Pr√°cticas Agroindustria:')\n","print('-' * 50)\n","print(prompt_A)\n","print('\\nüìù Prompt B (Few-shot) - Pr√°cticas Agroindustria:')\n","print('-' * 50)\n","print(prompt_B)"]},{"cell_type":"markdown","id":"1117fc73","metadata":{"id":"1117fc73"},"source":["## 4) Funci√≥n get_response adaptada a OpenAI\n","\n","La funci√≥n usa el endpoint de chat completions y retorna el texto generado."]},{"cell_type":"code","execution_count":null,"id":"f599e07b","metadata":{"id":"f599e07b"},"outputs":[],"source":["def get_response(\n","    prompt, model=\"gpt-4o-mini\", temperature=0.7, max_tokens=256\n","):\n","    \"\"\"\n","    Genera una respuesta usando OpenAI Chat Completions.\n","    Retorna el texto del assistant.\n","    \"\"\"\n","    try:\n","        # client.chat.completions.create retorna un objeto con choices\n","        response = client.chat.completions.create(\n","            model=model,\n","            messages=[{\"role\": \"user\", \"content\": prompt}],\n","            temperature=temperature,\n","            max_tokens=max_tokens,\n","        )\n","        # Acceder al contenido de la primera choice correctamente\n","        content = response.choices[0].message.content\n","        return content\n","    except Exception as e:\n","        # Manejo b√°sico de errores\n","        print(\"Error al generar respuesta:\", e)\n","        return None"]},{"cell_type":"markdown","id":"a99f8825","metadata":{"id":"a99f8825"},"source":["## 5) Ejecutar experimento: Generar respuestas para cada variante"]},{"cell_type":"code","execution_count":null,"id":"0e8774e9","metadata":{"id":"0e8774e9"},"outputs":[],"source":["test_prompts = [prompt_A, prompt_B]\n","responses = []\n","num_tests = 5\n","model_to_use = (\n","    \"gpt-4o-mini\"  # Cambia por gpt-4o o gpt-4o-mini seg√∫n disponibilidad y coste\n",")  # Cambia por gpt-4o o gpt-4o-mini seg√∫n disponibilidad y coste\n","\n","print('üöÄ Iniciando experimento A/B Testing con OpenAI...')\n","for idx, prompt in enumerate(test_prompts):\n","    var_name = chr(ord('A') + idx)\n","    print(f'üìä Generando respuestas para Variante {var_name}...')\n","    for i in range(num_tests):\n","        resp_text = get_response(prompt, model=model_to_use)\n","        data = {\n","            'variante': var_name,\n","            'prompt': prompt,\n","            'respuesta': resp_text\n","        }\n","        responses.append(data)\n","        print(f'  ‚úì Respuesta {i+1}/{num_tests} generada')\n","    print()\n","df = pd.DataFrame(responses)\n","df.to_csv('respuestas_openai.csv', index=False)\n","\n","print('üìÑ Resumen del experimento:')\n","print(f'Total de respuestas generadas: {len(df)}')\n","print(df.head())"]},{"cell_type":"markdown","id":"dbda9787","metadata":{"id":"dbda9787"},"source":["## 6) Interfaz de evaluaci√≥n humana (widgets)\n","\n","La interfaz es equivalente a la del cuaderno original. En Colab ipywidgets puede requerir instalaci√≥n/soporte adicional; en Jupyter Notebook / JupyterLab funciona de forma nativa si tienes `ipywidgets`."]},{"cell_type":"code","execution_count":null,"id":"7df90767","metadata":{"id":"7df90767"},"outputs":[],"source":["import ipywidgets as widgets\n","from IPython.display import display\n","\n","# Cargar el CSV guardado (por si reiniciaste el kernel)\n","df = pd.read_csv('respuestas_openai.csv')\n","df = df.sample(frac=1).reset_index(drop=True)  # mezclar para evaluaci√≥n ciega\n","df['feedback'] = pd.Series(dtype='float')\n","response_index = 0\n","\n","def update_response():\n","    global response_index\n","    new_response = df.iloc[response_index]['respuesta']\n","    if pd.notna(new_response):\n","        response.value = \"<p>\" + str(new_response) + \"</p>\"\n","    else:\n","        response.value = \"<p>Sin respuesta</p>\"\n","    count_label.value = f\"Respuesta: {response_index + 1}/{len(df)}\"\n","\n","def on_button_clicked(b):\n","    global response_index\n","    user_feedback = 1 if b.description == '\\U0001F44D' else 0\n","    df.at[response_index, 'feedback'] = user_feedback\n","    response_index += 1\n","    if response_index < len(df):\n","        update_response()\n","    else:\n","        df.to_csv('resultados_openai.csv', index=False)\n","        print('\\n‚úÖ Prueba A/B completada. Resultados guardados en resultados_openai.csv')\n","        summary_df = df.groupby('variante').agg(cantidad=('feedback', 'count'), puntuacion=('feedback', 'mean')).reset_index()\n","        print(summary_df)\n","\n","response = widgets.HTML()\n","count_label = widgets.Label()\n","update_response()\n","thumbs_up_button = widgets.Button(description='\\U0001F44D')\n","thumbs_up_button.on_click(on_button_clicked)\n","thumbs_down_button = widgets.Button(description='\\U0001F44E')\n","thumbs_down_button.on_click(on_button_clicked)\n","button_box = widgets.HBox([thumbs_down_button, thumbs_up_button])\n","print('üëá Eval√∫a cada respuesta usando los botones:')\n","display(response, button_box, count_label)"]},{"cell_type":"markdown","id":"ff6b2861","metadata":{"id":"ff6b2861"},"source":["## 7) Conclusiones y pr√≥ximos pasos\n","\n","- Incrementar el n√∫mero de iteraciones para mayor poder estad√≠stico\n","- Probar diferentes modelos (`gpt-3.5-turbo`, `gpt-4`, `gpt-4o`) para comparar coste/beneficio\n","- Guardar metadatos (temperatura, modelo) junto a cada respuesta para an√°lisis posterior\n","- Probar la ejecuci√≥n en Colab y en local para validar la carga de secrets"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}